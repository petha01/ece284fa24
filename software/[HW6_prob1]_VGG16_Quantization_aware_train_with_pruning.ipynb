{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a971d2d4-0fc2-496c-a963-a262f17d58fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Building model...\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import time\n",
    "import shutil\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn   \n",
    "\n",
    "import torch.nn.utils.prune as prune\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from models import *\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "global best_prec\n",
    "use_gpu = torch.cuda.is_available()\n",
    "print('=> Building model...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74e46199-c867-4822-bbc0-8f3386e0256c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "normalize = transforms.Normalize(mean=[0.491, 0.482, 0.447], std=[0.247, 0.243, 0.262])\n",
    "\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]))\n",
    "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]))\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "\n",
    "print_freq = 100 # every 100 batches, accuracy printed. Here, each batch includes \"batch_size\" data points\n",
    "# CIFAR10 has 50,000 training data, and 10,000 validation data.\n",
    "\n",
    "def train(trainloader, model, criterion, optimizer, epoch):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (input, target) in enumerate(trainloader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        input, target = input.cuda(), target.cuda()\n",
    "\n",
    "        # compute output\n",
    "        output = model(input)\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec = accuracy(output, target)[0]\n",
    "        losses.update(loss.item(), input.size(0))\n",
    "        top1.update(prec.item(), input.size(0))\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "\n",
    "        if i % print_freq == 0:\n",
    "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'Prec {top1.val:.3f}% ({top1.avg:.3f}%)'.format(\n",
    "                   epoch, i, len(trainloader), batch_time=batch_time,\n",
    "                   data_time=data_time, loss=losses, top1=top1))\n",
    "\n",
    "            \n",
    "\n",
    "def validate(val_loader, model, criterion ):\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    end = time.time()\n",
    "    with torch.no_grad():\n",
    "        for i, (input, target) in enumerate(val_loader):\n",
    "         \n",
    "            input, target = input.cuda(), target.cuda()\n",
    "\n",
    "            # compute output\n",
    "            output = model(input)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            prec = accuracy(output, target)[0]\n",
    "            losses.update(loss.item(), input.size(0))\n",
    "            top1.update(prec.item(), input.size(0))\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            if False and i % print_freq == 0:  # This line shows how frequently print out the status. e.g., i%5 => every 5 batch, prints out\n",
    "                print('Test: [{0}/{1}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'Prec {top1.val:.3f}% ({top1.avg:.3f}%)'.format(\n",
    "                   i, len(val_loader), batch_time=batch_time, loss=losses,\n",
    "                   top1=top1))\n",
    "\n",
    "    # print(' * Prec {top1.avg:.3f}% '.format(top1=top1))\n",
    "    return top1.avg\n",
    "\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].view(-1).float().sum(0)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "        \n",
    "def save_checkpoint(state, is_best, fdir):\n",
    "    filepath = os.path.join(fdir, 'checkpoint.pth')\n",
    "    torch.save(state, filepath)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filepath, os.path.join(fdir, 'model_best.pth.tar'))\n",
    "\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    \"\"\"For resnet, the lr starts from 0.1, and is divided by 10 at 80 and 120 epochs\"\"\"\n",
    "    adjust_list = [150, 225]\n",
    "    if epoch in adjust_list:\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = param_group['lr'] * 0.1        \n",
    "\n",
    "#model = nn.DataParallel(model).cuda()\n",
    "#all_params = checkpoint['state_dict']\n",
    "#model.load_state_dict(all_params, strict=False)\n",
    "#criterion = nn.CrossEntropyLoss().cuda()\n",
    "#validate(testloader, model, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b26f2600-645d-4c39-a28a-8c9f5d161139",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_gpu = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_gpu else \"cpu\") \n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "model_name = \"VGG16_quant\"\n",
    "model = VGG16_quant()\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "entertaining-queensland",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Accuracy: 9011/10000 (90%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "PATH = '/home/pnataraj/private/ece284_saved_models/vggnet_quant4/model_best.pth.tar'\n",
    "checkpoint = torch.load(PATH)\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "model.cuda()\n",
    "model.eval()\n",
    "\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, target in testloader:\n",
    "        data, target = data.to(device), target.to(device) # loading to GPU\n",
    "        output = model(data)\n",
    "        pred = output.argmax(dim=1, keepdim=True)  \n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "test_loss /= len(testloader.dataset)\n",
    "\n",
    "print('\\nTest set: Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        correct, len(testloader.dataset),\n",
    "        100. * correct / len(testloader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46cb8cbc-7b17-40b9-ae86-5c71882cc090",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_to_prune = tuple(\n",
    "    (module, 'weight') for name, module in model.named_modules()\n",
    "    if isinstance(module, (QuantConv2d))\n",
    ")\n",
    "\n",
    "for module, param_name in parameters_to_prune:\n",
    "    prune.l1_unstructured(module, name=param_name, amount=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28281653-608b-4526-b8d1-013d7ea28e0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sparsity: 0.8000\n"
     ]
    }
   ],
   "source": [
    "total_zeros = 0\n",
    "total_elements = 0\n",
    "\n",
    "for module, param_name in parameters_to_prune:\n",
    "    mask = getattr(module, f\"{param_name}_mask\")\n",
    "    \n",
    "    layer_sparsity = (mask == 0).sum() / mask.nelement()\n",
    "    \n",
    "    # Accumulate total zeros and elements\n",
    "    total_zeros += (mask == 0).sum()\n",
    "    total_elements += mask.nelement()\n",
    "\n",
    "total_sparsity = total_zeros / total_elements\n",
    "print(f\"Total sparsity: {total_sparsity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ceramic-nigeria",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity level:  tensor(0.8000, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "### Check sparsity ###\n",
    "mask1 = model.features[30].weight_mask\n",
    "sparsity_mask1 = (mask1 == 0).sum() / mask1.nelement()\n",
    "\n",
    "print(\"Sparsity level: \", sparsity_mask1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "acquired-vampire",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Accuracy: 1000/10000 (10%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## check accuracy after pruning\n",
    "\n",
    "model.eval()\n",
    "\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, target in testloader:\n",
    "        data, target = data.to(device), target.to(device) # loading to GPU\n",
    "        output = model(data)\n",
    "        pred = output.argmax(dim=1, keepdim=True)  \n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "test_loss /= len(testloader.dataset)\n",
    "\n",
    "print('\\nTest set: Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        correct, len(testloader.dataset),\n",
    "        100. * correct / len(testloader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "spoken-worst",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 0.945094\n",
      "Epoch: 2 \tTraining Loss: 0.379799\n",
      "Epoch: 3 \tTraining Loss: 0.305727\n",
      "Epoch: 4 \tTraining Loss: 0.272111\n",
      "Epoch: 5 \tTraining Loss: 0.246088\n",
      "Epoch: 6 \tTraining Loss: 0.222121\n",
      "Epoch: 7 \tTraining Loss: 0.211573\n",
      "Epoch: 8 \tTraining Loss: 0.198512\n",
      "Epoch: 9 \tTraining Loss: 0.185309\n",
      "Epoch: 10 \tTraining Loss: 0.178605\n",
      "Epoch: 11 \tTraining Loss: 0.169813\n",
      "Epoch: 12 \tTraining Loss: 0.162687\n",
      "Epoch: 13 \tTraining Loss: 0.157599\n",
      "Epoch: 14 \tTraining Loss: 0.155143\n",
      "Epoch: 15 \tTraining Loss: 0.148869\n",
      "Epoch: 16 \tTraining Loss: 0.839772\n",
      "Epoch: 17 \tTraining Loss: 0.404116\n",
      "Epoch: 18 \tTraining Loss: 0.339178\n",
      "Epoch: 19 \tTraining Loss: 0.306571\n",
      "Epoch: 20 \tTraining Loss: 0.279771\n"
     ]
    }
   ],
   "source": [
    "## Start finetuning (training here), and see how much you can recover your accuracy ##\n",
    "## You can change hyper parameters such as epochs or lr ##\n",
    "\n",
    "# number of epochs to train the model\n",
    "n_epochs = 20\n",
    "# per epoch, all the training data set is used once\n",
    "model.train() # prep model for training\n",
    "\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # monitor training loss\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    ###################\n",
    "    # train the model #\n",
    "    ###################\n",
    "    for data, target in trainloader:\n",
    "        data, target = data.to(device), target.to(device) # loading to GPU\n",
    "        # clear the gradients of all optimized variables\n",
    "        optimizer.zero_grad()\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        # calculate the loss\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()*data.size(0) # as loss is tensor, .item() needed to get the value\n",
    "        \n",
    "    # print training statistics \n",
    "    # calculate average loss over an epoch\n",
    "    train_loss = train_loss/len(trainloader.dataset)\n",
    "\n",
    "    if epoch % 5 == 0:\n",
    "        prec = validate(testloader, model, criterion)\n",
    "        if prec > 90:\n",
    "            break\n",
    "\n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f}'.format(epoch+1, train_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "thick-ready",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Accuracy: 8678/10000 (87%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## check your accuracy again after finetuning\n",
    "model.eval()\n",
    "\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, target in testloader:\n",
    "        data, target = data.to(device), target.to(device) # loading to GPU\n",
    "        output = model(data)\n",
    "        pred = output.argmax(dim=1, keepdim=True)  \n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "test_loss /= len(testloader.dataset)\n",
    "\n",
    "print('\\nTest set: Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        correct, len(testloader.dataset),\n",
    "        100. * correct / len(testloader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "driving-tanzania",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity level:  tensor(0.8004, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "## Send an image and use prehook to grab the inputs of all the QuantConv2d layers\n",
    "\n",
    "class SaveOutput:\n",
    "    def __init__(self):\n",
    "        self.outputs = []\n",
    "    def __call__(self, module, module_in):\n",
    "        self.outputs.append(module_in)\n",
    "    def clear(self):\n",
    "        self.outputs = []  \n",
    "        \n",
    "######### Save inputs from selected layer ##########\n",
    "save_output = SaveOutput()\n",
    "i = 0\n",
    "\n",
    "for layer in model.modules():\n",
    "    i = i+1\n",
    "    if isinstance(layer, QuantConv2d):\n",
    "        # print(i,\"-th layer prehooked\")\n",
    "        layer.register_forward_pre_hook(save_output)             \n",
    "####################################################\n",
    "\n",
    "dataiter = iter(testloader)\n",
    "images, labels = next(dataiter)\n",
    "images = images.to(device)\n",
    "out = model(images)\n",
    "\n",
    "##### Find \"weight_int\" for features[3] ####\n",
    "w_bit = 4\n",
    "weight_q = model.features[3].weight_q\n",
    "w_alpha = model.features[3].weight_quant.wgt_alpha\n",
    "w_delta = w_alpha /(2**(w_bit-1)-1)\n",
    "\n",
    "weight_int = weight_q / w_delta\n",
    "# print(weight_int)\n",
    "\n",
    "#### check your sparsity for weight_int is near 90% #####\n",
    "#### Your sparsity could be >90% after quantization #####\n",
    "sparsity_weight_int = (weight_int == 0).sum() / weight_int.nelement()\n",
    "print(\"Sparsity level: \", sparsity_weight_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a318414-7724-4da0-9340-7f3fca33b281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Structured Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "textile-cancer",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_gpu = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_gpu else \"cpu\") \n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "model_name = \"VGG16_quant\"\n",
    "model = VGG16_quant()\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "selected-excuse",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Accuracy: 9011/10000 (90%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "PATH = '/home/pnataraj/private/ece284_saved_models/vggnet_quant4/model_best.pth.tar'\n",
    "checkpoint = torch.load(PATH)\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "model.cuda()\n",
    "model.eval()\n",
    "\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, target in testloader:\n",
    "        data, target = data.to(device), target.to(device) # loading to GPU\n",
    "        output = model(data)\n",
    "        pred = output.argmax(dim=1, keepdim=True)  \n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "test_loss /= len(testloader.dataset)\n",
    "\n",
    "print('\\nTest set: Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        correct, len(testloader.dataset),\n",
    "        100. * correct / len(testloader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "designed-auction",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_to_prune = tuple(\n",
    "    (module, 'weight') for name, module in model.named_modules()\n",
    "    if isinstance(module, (QuantConv2d, torch.nn.Linear))\n",
    ")\n",
    "\n",
    "for module, param_name in parameters_to_prune:\n",
    "    prune.ln_structured(module, name=param_name, amount=0.8, dim=0, n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cc7d214a-da85-43df-9e24-f4df5faf013b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sparsity: 0.8007\n"
     ]
    }
   ],
   "source": [
    "total_zeros = 0\n",
    "total_elements = 0\n",
    "\n",
    "for module, param_name in parameters_to_prune:\n",
    "    mask = getattr(module, f\"{param_name}_mask\")\n",
    "    \n",
    "    layer_sparsity = (mask == 0).sum() / mask.nelement()\n",
    "    \n",
    "    # Accumulate total zeros and elements\n",
    "    total_zeros += (mask == 0).sum()\n",
    "    total_elements += mask.nelement()\n",
    "\n",
    "total_sparsity = total_zeros / total_elements\n",
    "print(f\"Total sparsity: {total_sparsity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "sorted-niger",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity level:  tensor(0.8008, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "### Check sparsity ###\n",
    "mask1 = model.features[30].weight_mask\n",
    "sparsity_mask1 = (mask1 == 0).sum() / mask1.nelement()\n",
    "\n",
    "print(\"Sparsity level: \", sparsity_mask1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "significant-whole",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Accuracy: 1000/10000 (10%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## check accuracy after pruning\n",
    "\n",
    "model.eval()\n",
    "\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, target in testloader:\n",
    "        data, target = data.to(device), target.to(device) # loading to GPU\n",
    "        output = model(data)\n",
    "        pred = output.argmax(dim=1, keepdim=True)  \n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "test_loss /= len(testloader.dataset)\n",
    "\n",
    "print('\\nTest set: Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        correct, len(testloader.dataset),\n",
    "        100. * correct / len(testloader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "corresponding-significance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 2.239174\n",
      "Epoch: 2 \tTraining Loss: 2.120419\n",
      "Epoch: 3 \tTraining Loss: 2.085715\n",
      "Epoch: 4 \tTraining Loss: 2.063122\n",
      "Epoch: 5 \tTraining Loss: 2.048908\n",
      "Epoch: 6 \tTraining Loss: 2.029553\n",
      "Epoch: 7 \tTraining Loss: 2.022855\n",
      "Epoch: 8 \tTraining Loss: 2.011730\n",
      "Epoch: 9 \tTraining Loss: 2.004261\n",
      "Epoch: 10 \tTraining Loss: 1.997845\n",
      "Epoch: 11 \tTraining Loss: 1.989787\n",
      "Epoch: 12 \tTraining Loss: 1.985239\n",
      "Epoch: 13 \tTraining Loss: 1.979255\n",
      "Epoch: 14 \tTraining Loss: 1.974969\n",
      "Epoch: 15 \tTraining Loss: 1.968753\n",
      "Epoch: 16 \tTraining Loss: 1.965929\n",
      "Epoch: 17 \tTraining Loss: 1.963270\n",
      "Epoch: 18 \tTraining Loss: 1.960023\n",
      "Epoch: 19 \tTraining Loss: 1.956689\n",
      "Epoch: 20 \tTraining Loss: 1.953394\n",
      "Epoch: 21 \tTraining Loss: 1.950095\n",
      "Epoch: 22 \tTraining Loss: 1.949123\n",
      "Epoch: 23 \tTraining Loss: 1.945882\n",
      "Epoch: 24 \tTraining Loss: 1.943602\n",
      "Epoch: 25 \tTraining Loss: 1.940296\n",
      "Epoch: 26 \tTraining Loss: 1.937712\n",
      "Epoch: 27 \tTraining Loss: 1.933638\n",
      "Epoch: 28 \tTraining Loss: 1.930301\n",
      "Epoch: 29 \tTraining Loss: 1.930526\n",
      "Epoch: 30 \tTraining Loss: 1.927221\n",
      "Epoch: 31 \tTraining Loss: 1.925364\n",
      "Epoch: 32 \tTraining Loss: 1.922758\n",
      "Epoch: 33 \tTraining Loss: 1.920787\n",
      "Epoch: 34 \tTraining Loss: 1.921109\n",
      "Epoch: 35 \tTraining Loss: 1.918558\n",
      "Epoch: 36 \tTraining Loss: 1.917448\n",
      "Epoch: 37 \tTraining Loss: 1.915954\n",
      "Epoch: 38 \tTraining Loss: 1.918241\n",
      "Epoch: 39 \tTraining Loss: 1.915012\n",
      "Epoch: 40 \tTraining Loss: 1.913217\n"
     ]
    }
   ],
   "source": [
    "## Start finetuning (training here), and see how much you can recover your accuracy ##\n",
    "## You can change hyper parameters such as epochs or lr ##\n",
    "\n",
    "# number of epochs to train the model\n",
    "n_epochs = 40\n",
    "# per epoch, all the training data set is used once\n",
    "model.train() # prep model for training\n",
    "\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # monitor training loss\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    ###################\n",
    "    # train the model #\n",
    "    ###################\n",
    "    for data, target in trainloader:\n",
    "        data, target = data.to(device), target.to(device) # loading to GPU\n",
    "        # clear the gradients of all optimized variables\n",
    "        optimizer.zero_grad()\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        # calculate the loss\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()*data.size(0) # as loss is tensor, .item() needed to get the value\n",
    "        \n",
    "    # print training statistics \n",
    "    # calculate average loss over an epoch\n",
    "    train_loss = train_loss/len(trainloader.dataset)\n",
    "\n",
    "    if epoch % 5 == 0:\n",
    "        prec = validate(testloader, model, criterion)\n",
    "        if prec > 90:\n",
    "            break\n",
    "\n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f}'.format(epoch+1, train_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "exposed-witch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Accuracy: 2396/10000 (24%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## check your accuracy again after finetuning\n",
    "model.eval()\n",
    "\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, target in testloader:\n",
    "        data, target = data.to(device), target.to(device) # loading to GPU\n",
    "        output = model(data)\n",
    "        pred = output.argmax(dim=1, keepdim=True)  \n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "test_loss /= len(testloader.dataset)\n",
    "\n",
    "print('\\nTest set: Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        correct, len(testloader.dataset),\n",
    "        100. * correct / len(testloader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "minimal-serbia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity level:  tensor(0.8318, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "## Send an image and use prehook to grab the inputs of all the QuantConv2d layers\n",
    "\n",
    "class SaveOutput:\n",
    "    def __init__(self):\n",
    "        self.outputs = []\n",
    "    def __call__(self, module, module_in):\n",
    "        self.outputs.append(module_in)\n",
    "    def clear(self):\n",
    "        self.outputs = []  \n",
    "        \n",
    "######### Save inputs from selected layer ##########\n",
    "save_output = SaveOutput()\n",
    "i = 0\n",
    "\n",
    "for layer in model.modules():\n",
    "    i = i+1\n",
    "    if isinstance(layer, QuantConv2d):\n",
    "        # print(i,\"-th layer prehooked\")\n",
    "        layer.register_forward_pre_hook(save_output)             \n",
    "####################################################\n",
    "\n",
    "dataiter = iter(testloader)\n",
    "images, labels = next(dataiter)\n",
    "images = images.to(device)\n",
    "out = model(images)\n",
    "\n",
    "##### Find \"weight_int\" for features[3] ####\n",
    "w_bit = 4\n",
    "weight_q = model.features[3].weight_q\n",
    "w_alpha = model.features[3].weight_quant.wgt_alpha\n",
    "w_delta = w_alpha /(2**(w_bit-1)-1)\n",
    "\n",
    "weight_int = weight_q / w_delta\n",
    "# print(weight_int)\n",
    "\n",
    "#### check your sparsity for weight_int is near 90% #####\n",
    "#### Your sparsity could be >90% after quantization #####\n",
    "sparsity_weight_int = (weight_int == 0).sum() / weight_int.nelement()\n",
    "print(\"Sparsity level: \", sparsity_weight_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521fdf38-2c5a-4f65-a72d-847ec42d6655",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
