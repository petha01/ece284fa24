{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24030b67-3322-4256-a312-e801a7ac9b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torchvision import datasets\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "\n",
    "from models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23e15dac-c681-43a3-804e-49a7acf3fe2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_gpu = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_gpu else \"cpu\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61120068-725c-42de-8c4f-811774bea155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "normalize = transforms.Normalize(mean=[0.491, 0.482, 0.447], std=[0.247, 0.243, 0.262])\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]))\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]))\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0575c52d-68df-4940-aa96-2782ca52942e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 125  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8317148c-dae4-4689-9a05-3b5dbe10b80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############\n",
    "# LOSS 1 ONLY #\n",
    "###############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f5596d2-6b74-45e2-8d22-8e1e53e6ad7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"vggnet16_cost0\"\n",
    "model = VGG16()\n",
    "PATH = '/home/pnataraj/private/ece284_saved_models/'+str(model_name)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "712205ea-ab3c-4f1d-beb6-4acb3819d461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 1.474318\n",
      "Epoch: 11 \tTraining Loss: 0.403917\n",
      "Epoch: 21 \tTraining Loss: 0.229810\n",
      "Epoch: 31 \tTraining Loss: 0.139805\n",
      "Epoch: 41 \tTraining Loss: 0.086677\n",
      "Epoch: 51 \tTraining Loss: 0.062855\n",
      "Epoch: 61 \tTraining Loss: 0.041610\n",
      "Epoch: 71 \tTraining Loss: 0.033780\n",
      "Epoch: 81 \tTraining Loss: 0.026193\n",
      "Epoch: 91 \tTraining Loss: 0.022190\n",
      "Epoch: 101 \tTraining Loss: 0.016597\n",
      "Epoch: 111 \tTraining Loss: 0.014777\n",
      "Epoch: 121 \tTraining Loss: 0.013584\n"
     ]
    }
   ],
   "source": [
    "# number of epochs to train the model\n",
    "model.to(device)\n",
    "# per epoch, all the training data set is used once\n",
    "model.train() # prep model for training\n",
    "\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # monitor training loss\n",
    "    train_loss = 0.0\n",
    "    train_loss1 = 0.0\n",
    "    train_loss2 = 0.0\n",
    "    \n",
    "    ###################\n",
    "    # train the model #\n",
    "    ###################\n",
    "    for data, target in train_loader:\n",
    "        data, target = data.to(device), target.to(device) # loading to GPU\n",
    "        # clear the gradients of all optimized variables\n",
    "        optimizer.zero_grad()\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        # calculate the loss\n",
    "        \n",
    "        loss1 = criterion(output, target)\n",
    "        loss2 = model.features[0].weight.abs().sum()\n",
    "\n",
    "        #loss = loss1\n",
    "        loss = loss1 + 0*loss2  # Only use loss 1\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss1 += loss1.item()*data.size(0) # as loss is tensor, .item() needed to get the value\n",
    "        train_loss2 += loss2.item()*data.size(0) # as loss is tensor, .item() needed to get the value\n",
    "        train_loss  += loss.item()*data.size(0) # as loss is tensor, .item() needed to get the value\n",
    "        \n",
    "    # print training statistics \n",
    "    # calculate average loss over an epoch\n",
    "    train_loss1 = train_loss1/len(train_loader.dataset)\n",
    "    train_loss2 = train_loss2/len(train_loader.dataset)\n",
    "    train_loss = train_loss/len(train_loader.dataset)\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        # print('Epoch: {} \\tTraining Loss1: {:.6f}'.format(epoch+1, train_loss1))\n",
    "        # print('Epoch: {} \\tTraining Loss2: {:.6f}'.format(epoch+1, train_loss2))\n",
    "        print('Epoch: {} \\tTraining Loss: {:.6f}'.format(epoch+1, train_loss))\n",
    "    \n",
    "# see following link for details of state_dict   \n",
    "# https://pytorch.org/tutorials/recipes/recipes/saving_and_loading_a_general_checkpoint.html\n",
    "torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': train_loss,\n",
    "            }, PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d9f5faa-1b93-48de-9d5e-16d067959fe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Accuracy: 8961/10000 (90%)\n",
      "\n",
      "first conv layer weight absolute sum: 183.23004150390625\n"
     ]
    }
   ],
   "source": [
    "PATH = '/home/pnataraj/private/ece284_saved_models/vggnet16_cost0'\n",
    "model = VGG16()\n",
    "model.to(device)\n",
    "checkpoint = torch.load(PATH)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "train_loss = checkpoint['loss']\n",
    "\n",
    "model.eval()\n",
    "\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "        data, target = data.to(device), target.to(device) # loading to GPU\n",
    "        output = model(data)\n",
    "        pred = output.argmax(dim=1, keepdim=True)  \n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "test_loss /= len(test_loader.dataset)\n",
    "\n",
    "print('\\nTest set: Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "\n",
    "print('first conv layer weight absolute sum:', model.features[0].weight.abs().sum().data.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11a76bd0-2d9e-4a77-9504-50e5090dc923",
   "metadata": {},
   "outputs": [],
   "source": [
    "################\n",
    "# LOSS 2 and 1 #\n",
    "################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d3d963e-6160-40d3-8c26-a510865bc60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"vggnet16_cost1\"\n",
    "model = VGG16()\n",
    "PATH = '/home/pnataraj/private/ece284_saved_models/'+str(model_name)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ade007bf-23a4-4316-9f35-ce2e6fb4e291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss1: 1.922165\n",
      "Epoch: 1 \tTraining Loss2: 13.396772\n",
      "Epoch: 1 \tTraining Loss: 15.318937\n",
      "Epoch: 11 \tTraining Loss1: 0.968684\n",
      "Epoch: 11 \tTraining Loss2: 10.753299\n",
      "Epoch: 11 \tTraining Loss: 11.721982\n",
      "Epoch: 21 \tTraining Loss1: 0.701288\n",
      "Epoch: 21 \tTraining Loss2: 10.422272\n",
      "Epoch: 21 \tTraining Loss: 11.123561\n",
      "Epoch: 31 \tTraining Loss1: 0.542433\n",
      "Epoch: 31 \tTraining Loss2: 10.079826\n",
      "Epoch: 31 \tTraining Loss: 10.622258\n",
      "Epoch: 41 \tTraining Loss1: 0.426482\n",
      "Epoch: 41 \tTraining Loss2: 10.187684\n",
      "Epoch: 41 \tTraining Loss: 10.614166\n",
      "Epoch: 51 \tTraining Loss1: 0.343424\n",
      "Epoch: 51 \tTraining Loss2: 10.011103\n",
      "Epoch: 51 \tTraining Loss: 10.354527\n",
      "Epoch: 61 \tTraining Loss1: 0.277458\n",
      "Epoch: 61 \tTraining Loss2: 10.261899\n",
      "Epoch: 61 \tTraining Loss: 10.539358\n",
      "Epoch: 71 \tTraining Loss1: 0.207878\n",
      "Epoch: 71 \tTraining Loss2: 10.294593\n",
      "Epoch: 71 \tTraining Loss: 10.502471\n",
      "Epoch: 81 \tTraining Loss1: 0.184922\n",
      "Epoch: 81 \tTraining Loss2: 9.908035\n",
      "Epoch: 81 \tTraining Loss: 10.092956\n",
      "Epoch: 91 \tTraining Loss1: 0.129020\n",
      "Epoch: 91 \tTraining Loss2: 11.054777\n",
      "Epoch: 91 \tTraining Loss: 11.183797\n",
      "Epoch: 101 \tTraining Loss1: 0.124988\n",
      "Epoch: 101 \tTraining Loss2: 9.750807\n",
      "Epoch: 101 \tTraining Loss: 9.875795\n",
      "Epoch: 111 \tTraining Loss1: 0.099060\n",
      "Epoch: 111 \tTraining Loss2: 10.353419\n",
      "Epoch: 111 \tTraining Loss: 10.452479\n",
      "Epoch: 121 \tTraining Loss1: 0.085257\n",
      "Epoch: 121 \tTraining Loss2: 10.110666\n",
      "Epoch: 121 \tTraining Loss: 10.195923\n"
     ]
    }
   ],
   "source": [
    "# number of epochs to train the model \n",
    "model.to(device)\n",
    "# per epoch, all the training data set is used once\n",
    "model.train() # prep model for training\n",
    "\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # monitor training loss\n",
    "    train_loss = 0.0\n",
    "    train_loss1 = 0.0\n",
    "    train_loss2 = 0.0\n",
    "    \n",
    "    ###################\n",
    "    # train the model #\n",
    "    ###################\n",
    "    for data, target in train_loader:\n",
    "        data, target = data.to(device), target.to(device) # loading to GPU\n",
    "        # clear the gradients of all optimized variables\n",
    "        optimizer.zero_grad()\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        # calculate the loss\n",
    "        \n",
    "        loss1 = criterion(output, target)\n",
    "        loss2 = model.features[0].weight.abs().sum()\n",
    "\n",
    "        #loss = loss1\n",
    "        loss = loss1 + loss2\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss1 += loss1.item()*data.size(0) # as loss is tensor, .item() needed to get the value\n",
    "        train_loss2 += loss2.item()*data.size(0) # as loss is tensor, .item() needed to get the value\n",
    "        train_loss  += loss.item()*data.size(0) # as loss is tensor, .item() needed to get the value\n",
    "        \n",
    "    # print training statistics \n",
    "    # calculate average loss over an epoch\n",
    "    train_loss1 = train_loss1/len(train_loader.dataset)\n",
    "    train_loss2 = train_loss2/len(train_loader.dataset)\n",
    "    train_loss = train_loss/len(train_loader.dataset)\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print('Epoch: {} \\tTraining Loss1: {:.6f}'.format(epoch+1, train_loss1))\n",
    "        print('Epoch: {} \\tTraining Loss2: {:.6f}'.format(epoch+1, train_loss2))\n",
    "        print('Epoch: {} \\tTraining Loss: {:.6f}'.format(epoch+1, train_loss))\n",
    "    \n",
    "# see following link for details of state_dict   \n",
    "# https://pytorch.org/tutorials/recipes/recipes/saving_and_loading_a_general_checkpoint.html\n",
    "torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': train_loss,\n",
    "            }, PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ed0b47e-2d66-452c-bac5-a6ce85ac1dd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Accuracy: 6731/10000 (67%)\n",
      "\n",
      "first conv layer weight absolute sum: 9.882144927978516\n"
     ]
    }
   ],
   "source": [
    "PATH = '/home/pnataraj/private/ece284_saved_models/vggnet16_cost1'\n",
    "model = VGG16()\n",
    "model.to(device)\n",
    "checkpoint = torch.load(PATH)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "train_loss = checkpoint['loss']\n",
    "\n",
    "model.eval()\n",
    "\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "        data, target = data.to(device), target.to(device) # loading to GPU\n",
    "        output = model(data)\n",
    "        pred = output.argmax(dim=1, keepdim=True)  \n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "test_loss /= len(test_loader.dataset)\n",
    "\n",
    "print('\\nTest set: Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "print('first conv layer weight absolute sum:', model.features[0].weight.abs().sum().data.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a67dc721-948c-488f-b710-8eaea60e1a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################\n",
    "# LOSS optimized 2 #\n",
    "####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f74ac01-3a77-4cd5-8624-2af9a0774427",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"vggnet16_cost2\"\n",
    "model = VGG16()\n",
    "PATH = '/home/pnataraj/private/ece284_saved_models/'+str(model_name)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f50b9c63-3332-4d95-bb3d-473c28aa7564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss1: 1.476671\n",
      "Epoch: 1 \tTraining Loss2: 136.600283\n",
      "Epoch: 1 \tTraining Loss: 2.842674\n",
      "Epoch: 11 \tTraining Loss1: 0.478637\n",
      "Epoch: 11 \tTraining Loss2: 9.025821\n",
      "Epoch: 11 \tTraining Loss: 0.568895\n",
      "Epoch: 21 \tTraining Loss1: 0.299440\n",
      "Epoch: 21 \tTraining Loss2: 7.888343\n",
      "Epoch: 21 \tTraining Loss: 0.378324\n",
      "Epoch: 31 \tTraining Loss1: 0.194817\n",
      "Epoch: 31 \tTraining Loss2: 7.226530\n",
      "Epoch: 31 \tTraining Loss: 0.267083\n",
      "Epoch: 41 \tTraining Loss1: 0.129657\n",
      "Epoch: 41 \tTraining Loss2: 6.657391\n",
      "Epoch: 41 \tTraining Loss: 0.196231\n",
      "Epoch: 51 \tTraining Loss1: 0.094112\n",
      "Epoch: 51 \tTraining Loss2: 6.453971\n",
      "Epoch: 51 \tTraining Loss: 0.158652\n",
      "Epoch: 61 \tTraining Loss1: 0.072539\n",
      "Epoch: 61 \tTraining Loss2: 6.144388\n",
      "Epoch: 61 \tTraining Loss: 0.133983\n",
      "Epoch: 71 \tTraining Loss1: 0.054878\n",
      "Epoch: 71 \tTraining Loss2: 5.635196\n",
      "Epoch: 71 \tTraining Loss: 0.111229\n",
      "Epoch: 81 \tTraining Loss1: 0.048332\n",
      "Epoch: 81 \tTraining Loss2: 5.582943\n",
      "Epoch: 81 \tTraining Loss: 0.104161\n",
      "Epoch: 91 \tTraining Loss1: 0.038770\n",
      "Epoch: 91 \tTraining Loss2: 5.344524\n",
      "Epoch: 91 \tTraining Loss: 0.092215\n",
      "Epoch: 101 \tTraining Loss1: 0.031564\n",
      "Epoch: 101 \tTraining Loss2: 4.861581\n",
      "Epoch: 101 \tTraining Loss: 0.080180\n",
      "Epoch: 111 \tTraining Loss1: 0.027063\n",
      "Epoch: 111 \tTraining Loss2: 4.713744\n",
      "Epoch: 111 \tTraining Loss: 0.074200\n",
      "Epoch: 121 \tTraining Loss1: 0.025711\n",
      "Epoch: 121 \tTraining Loss2: 4.800200\n",
      "Epoch: 121 \tTraining Loss: 0.073713\n"
     ]
    }
   ],
   "source": [
    "# number of epochs to train the model\n",
    "model.to(device)\n",
    "# per epoch, all the training data set is used once\n",
    "model.train() # prep model for training\n",
    "\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # monitor training loss\n",
    "    train_loss = 0.0\n",
    "    train_loss1 = 0.0\n",
    "    train_loss2 = 0.0\n",
    "    \n",
    "    ###################\n",
    "    # train the model #\n",
    "    ###################\n",
    "    for data, target in train_loader:\n",
    "        data, target = data.to(device), target.to(device) # loading to GPU\n",
    "        # clear the gradients of all optimized variables\n",
    "        optimizer.zero_grad()\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        # calculate the loss\n",
    "        \n",
    "        loss1 = criterion(output, target)\n",
    "        loss2 = model.features[0].weight.abs().sum()\n",
    "\n",
    "        #loss = loss1\n",
    "        loss = loss1 + 0.01*loss2\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss1 += loss1.item()*data.size(0) # as loss is tensor, .item() needed to get the value\n",
    "        train_loss2 += loss2.item()*data.size(0) # as loss is tensor, .item() needed to get the value\n",
    "        train_loss  += loss.item()*data.size(0) # as loss is tensor, .item() needed to get the value\n",
    "        \n",
    "    # print training statistics \n",
    "    # calculate average loss over an epoch\n",
    "    train_loss1 = train_loss1/len(train_loader.dataset)\n",
    "    train_loss2 = train_loss2/len(train_loader.dataset)\n",
    "    train_loss = train_loss/len(train_loader.dataset)\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print('Epoch: {} \\tTraining Loss1: {:.6f}'.format(epoch+1, train_loss1))\n",
    "        print('Epoch: {} \\tTraining Loss2: {:.6f}'.format(epoch+1, train_loss2))\n",
    "        print('Epoch: {} \\tTraining Loss: {:.6f}'.format(epoch+1, train_loss))\n",
    "    \n",
    "# see following link for details of state_dict   \n",
    "# https://pytorch.org/tutorials/recipes/recipes/saving_and_loading_a_general_checkpoint.html\n",
    "torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': train_loss,\n",
    "            }, PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ab9366c-4935-41cc-8a3e-dfedbc119699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Accuracy: 8627/10000 (86%)\n",
      "\n",
      "first conv layer weight absolute sum: 4.874133110046387\n"
     ]
    }
   ],
   "source": [
    "PATH = '/home/pnataraj/private/ece284_saved_models/vggnet16_cost2'\n",
    "model = VGG16()\n",
    "model.to(device)\n",
    "checkpoint = torch.load(PATH)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "train_loss = checkpoint['loss']\n",
    "\n",
    "model.eval()\n",
    "\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "        data, target = data.to(device), target.to(device) # loading to GPU\n",
    "        output = model(data)\n",
    "        pred = output.argmax(dim=1, keepdim=True)  \n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "test_loss /= len(test_loader.dataset)\n",
    "\n",
    "print('\\nTest set: Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "\n",
    "print('first conv layer weight absolute sum:', model.features[0].weight.abs().sum().data.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf91646-80ce-4486-9eb5-1b56b8932ad2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
