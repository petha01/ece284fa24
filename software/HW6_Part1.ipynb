{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "13dceb56-3ba5-4558-bec1-24a3e7fbfc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import time\n",
    "import shutil\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "     \n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from models import *\n",
    "\n",
    "global best_prec\n",
    "use_gpu = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54e13774-bc01-43e4-a8bc-8fe3142d2435",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "266e8374-a448-4de8-a0f4-7e2907b858dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "normalize = transforms.Normalize(mean=[0.491, 0.482, 0.447], std=[0.247, 0.243, 0.262])\n",
    "\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]))\n",
    "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]))\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71a2daf0-bd19-4600-b95f-4169de6b36e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_freq = 300\n",
    "\n",
    "def train(trainloader, model, criterion, optimizer, epoch):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (input, target) in enumerate(trainloader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        input, target = input.cuda(), target.cuda()\n",
    "\n",
    "        # compute output\n",
    "        output = model(input)\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec = accuracy(output, target)[0]\n",
    "        losses.update(loss.item(), input.size(0))\n",
    "        top1.update(prec.item(), input.size(0))\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "\n",
    "        if i % print_freq == 0:\n",
    "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'Prec {top1.val:.3f}% ({top1.avg:.3f}%)'.format(\n",
    "                   epoch, i, len(trainloader), batch_time=batch_time,\n",
    "                   data_time=data_time, loss=losses, top1=top1))\n",
    "\n",
    "            \n",
    "\n",
    "def validate(val_loader, model, criterion ):\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    end = time.time()\n",
    "    with torch.no_grad():\n",
    "        for i, (input, target) in enumerate(val_loader):\n",
    "         \n",
    "            input, target = input.cuda(), target.cuda()\n",
    "\n",
    "            # compute output\n",
    "            output = model(input)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            prec = accuracy(output, target)[0]\n",
    "            losses.update(loss.item(), input.size(0))\n",
    "            top1.update(prec.item(), input.size(0))\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            if i % print_freq == 0:  # This line shows how frequently print out the status. e.g., i%5 => every 5 batch, prints out\n",
    "                print('Test: [{0}/{1}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'Prec {top1.val:.3f}% ({top1.avg:.3f}%)'.format(\n",
    "                   i, len(val_loader), batch_time=batch_time, loss=losses,\n",
    "                   top1=top1))\n",
    "\n",
    "    print(' * Prec {top1.avg:.3f}% '.format(top1=top1))\n",
    "    return top1.avg\n",
    "\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].view(-1).float().sum(0)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "        \n",
    "def save_checkpoint(state, is_best, fdir):\n",
    "    filepath = os.path.join(fdir, 'checkpoint.pth')\n",
    "    torch.save(state, filepath)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filepath, os.path.join(fdir, 'model_best.pth.tar'))\n",
    "\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    \"\"\"For resnet, the lr starts from 0.1, and is divided by 10 at 80 and 120 epochs\"\"\"\n",
    "    adjust_list = [80, 120]\n",
    "    if epoch in adjust_list:\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = param_group['lr'] * 0.1        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e84431a6-49c6-4e01-8813-d235e34f5b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"vggnet_quant4\"\n",
    "model = model = VGG16_quant()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e2ab350-3fd9-4376-b7c5-68248566a6f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][0/391]\tTime 3.143 (3.143)\tData 0.324 (0.324)\tLoss 2.5531 (2.5531)\tPrec 13.281% (13.281%)\n",
      "Epoch: [0][300/391]\tTime 0.053 (0.066)\tData 0.002 (0.003)\tLoss 2.0975 (2.5160)\tPrec 14.844% (13.982%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.366 (0.366)\tLoss 2.0181 (2.0181)\tPrec 25.781% (25.781%)\n",
      " * Prec 19.190% \n",
      "best acc: 19.190000\n",
      "Epoch: [1][0/391]\tTime 0.412 (0.412)\tData 0.357 (0.357)\tLoss 2.1135 (2.1135)\tPrec 21.094% (21.094%)\n",
      "Epoch: [1][300/391]\tTime 0.063 (0.057)\tData 0.020 (0.003)\tLoss 1.8699 (2.0046)\tPrec 24.219% (23.580%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.469 (0.469)\tLoss 1.8918 (1.8918)\tPrec 32.031% (32.031%)\n",
      " * Prec 28.420% \n",
      "best acc: 28.420000\n",
      "Epoch: [2][0/391]\tTime 0.422 (0.422)\tData 0.370 (0.370)\tLoss 1.8891 (1.8891)\tPrec 23.438% (23.438%)\n",
      "Epoch: [2][300/391]\tTime 0.056 (0.057)\tData 0.002 (0.003)\tLoss 1.7746 (1.7850)\tPrec 32.031% (31.655%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.386 (0.386)\tLoss 1.7553 (1.7553)\tPrec 35.938% (35.938%)\n",
      " * Prec 36.310% \n",
      "best acc: 36.310000\n",
      "Epoch: [3][0/391]\tTime 0.487 (0.487)\tData 0.433 (0.433)\tLoss 1.6889 (1.6889)\tPrec 33.594% (33.594%)\n",
      "Epoch: [3][300/391]\tTime 0.055 (0.057)\tData 0.001 (0.003)\tLoss 1.4269 (1.6015)\tPrec 46.094% (39.073%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.348 (0.348)\tLoss 1.6697 (1.6697)\tPrec 39.844% (39.844%)\n",
      " * Prec 40.600% \n",
      "best acc: 40.600000\n",
      "Epoch: [4][0/391]\tTime 0.429 (0.429)\tData 0.373 (0.373)\tLoss 1.4017 (1.4017)\tPrec 45.312% (45.312%)\n",
      "Epoch: [4][300/391]\tTime 0.055 (0.057)\tData 0.002 (0.003)\tLoss 1.1960 (1.3943)\tPrec 52.344% (48.043%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.395 (0.395)\tLoss 1.3685 (1.3685)\tPrec 58.594% (58.594%)\n",
      " * Prec 44.190% \n",
      "best acc: 44.190000\n",
      "Epoch: [5][0/391]\tTime 0.471 (0.471)\tData 0.415 (0.415)\tLoss 1.3157 (1.3157)\tPrec 52.344% (52.344%)\n",
      "Epoch: [5][300/391]\tTime 0.055 (0.057)\tData 0.001 (0.003)\tLoss 1.1431 (1.2256)\tPrec 57.812% (54.934%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.380 (0.380)\tLoss 1.0287 (1.0287)\tPrec 62.500% (62.500%)\n",
      " * Prec 59.980% \n",
      "best acc: 59.980000\n",
      "Epoch: [6][0/391]\tTime 0.401 (0.401)\tData 0.350 (0.350)\tLoss 1.0634 (1.0634)\tPrec 62.500% (62.500%)\n",
      "Epoch: [6][300/391]\tTime 0.055 (0.056)\tData 0.002 (0.003)\tLoss 0.9498 (1.0700)\tPrec 64.844% (61.651%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.367 (0.367)\tLoss 1.0064 (1.0064)\tPrec 55.469% (55.469%)\n",
      " * Prec 63.490% \n",
      "best acc: 63.490000\n",
      "Epoch: [7][0/391]\tTime 0.514 (0.514)\tData 0.451 (0.451)\tLoss 1.0092 (1.0092)\tPrec 66.406% (66.406%)\n",
      "Epoch: [7][300/391]\tTime 0.055 (0.057)\tData 0.003 (0.004)\tLoss 0.8946 (0.9405)\tPrec 71.875% (66.764%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.318 (0.318)\tLoss 0.7939 (0.7939)\tPrec 70.312% (70.312%)\n",
      " * Prec 67.400% \n",
      "best acc: 67.400000\n",
      "Epoch: [8][0/391]\tTime 0.439 (0.439)\tData 0.381 (0.381)\tLoss 0.7800 (0.7800)\tPrec 69.531% (69.531%)\n",
      "Epoch: [8][300/391]\tTime 0.055 (0.057)\tData 0.001 (0.003)\tLoss 0.8713 (0.8402)\tPrec 68.750% (70.616%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.311 (0.311)\tLoss 0.6485 (0.6485)\tPrec 76.562% (76.562%)\n",
      " * Prec 71.740% \n",
      "best acc: 71.740000\n",
      "Epoch: [9][0/391]\tTime 0.442 (0.442)\tData 0.390 (0.390)\tLoss 0.8933 (0.8933)\tPrec 71.094% (71.094%)\n",
      "Epoch: [9][300/391]\tTime 0.055 (0.057)\tData 0.001 (0.003)\tLoss 0.8427 (0.7493)\tPrec 68.750% (74.107%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.409 (0.409)\tLoss 0.7101 (0.7101)\tPrec 75.781% (75.781%)\n",
      " * Prec 72.830% \n",
      "best acc: 72.830000\n",
      "Epoch: [10][0/391]\tTime 0.413 (0.413)\tData 0.354 (0.354)\tLoss 0.6502 (0.6502)\tPrec 82.031% (82.031%)\n",
      "Epoch: [10][300/391]\tTime 0.059 (0.056)\tData 0.001 (0.003)\tLoss 0.7367 (0.6868)\tPrec 75.000% (76.466%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.393 (0.393)\tLoss 0.7123 (0.7123)\tPrec 75.000% (75.000%)\n",
      " * Prec 72.510% \n",
      "best acc: 72.830000\n",
      "Epoch: [11][0/391]\tTime 0.415 (0.415)\tData 0.372 (0.372)\tLoss 0.6439 (0.6439)\tPrec 78.906% (78.906%)\n",
      "Epoch: [11][300/391]\tTime 0.055 (0.056)\tData 0.001 (0.003)\tLoss 0.6664 (0.6427)\tPrec 72.656% (77.998%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.301 (0.301)\tLoss 0.6342 (0.6342)\tPrec 77.344% (77.344%)\n",
      " * Prec 77.530% \n",
      "best acc: 77.530000\n",
      "Epoch: [12][0/391]\tTime 0.334 (0.334)\tData 0.292 (0.292)\tLoss 0.7242 (0.7242)\tPrec 72.656% (72.656%)\n",
      "Epoch: [12][300/391]\tTime 0.055 (0.057)\tData 0.001 (0.003)\tLoss 0.7593 (0.6030)\tPrec 72.656% (79.441%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.397 (0.397)\tLoss 0.5602 (0.5602)\tPrec 82.812% (82.812%)\n",
      " * Prec 79.030% \n",
      "best acc: 79.030000\n",
      "Epoch: [13][0/391]\tTime 0.443 (0.443)\tData 0.391 (0.391)\tLoss 0.6211 (0.6211)\tPrec 76.562% (76.562%)\n",
      "Epoch: [13][300/391]\tTime 0.055 (0.056)\tData 0.002 (0.003)\tLoss 0.5686 (0.5631)\tPrec 79.688% (80.804%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.370 (0.370)\tLoss 0.5908 (0.5908)\tPrec 77.344% (77.344%)\n",
      " * Prec 76.320% \n",
      "best acc: 79.030000\n",
      "Epoch: [14][0/391]\tTime 0.455 (0.455)\tData 0.404 (0.404)\tLoss 0.7664 (0.7664)\tPrec 77.344% (77.344%)\n",
      "Epoch: [14][300/391]\tTime 0.056 (0.057)\tData 0.002 (0.003)\tLoss 0.5281 (0.5284)\tPrec 82.031% (81.966%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.400 (0.400)\tLoss 0.4625 (0.4625)\tPrec 85.156% (85.156%)\n",
      " * Prec 82.220% \n",
      "best acc: 82.220000\n",
      "Epoch: [15][0/391]\tTime 0.404 (0.404)\tData 0.351 (0.351)\tLoss 0.3758 (0.3758)\tPrec 89.062% (89.062%)\n",
      "Epoch: [15][300/391]\tTime 0.055 (0.057)\tData 0.002 (0.003)\tLoss 0.3641 (0.4972)\tPrec 86.719% (83.127%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.369 (0.369)\tLoss 0.5608 (0.5608)\tPrec 78.906% (78.906%)\n",
      " * Prec 79.510% \n",
      "best acc: 82.220000\n",
      "Epoch: [16][0/391]\tTime 0.405 (0.405)\tData 0.354 (0.354)\tLoss 0.4359 (0.4359)\tPrec 85.938% (85.938%)\n",
      "Epoch: [16][300/391]\tTime 0.057 (0.056)\tData 0.002 (0.003)\tLoss 0.4610 (0.4763)\tPrec 85.938% (83.791%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.430 (0.430)\tLoss 0.4174 (0.4174)\tPrec 85.156% (85.156%)\n",
      " * Prec 83.480% \n",
      "best acc: 83.480000\n",
      "Epoch: [17][0/391]\tTime 0.418 (0.418)\tData 0.358 (0.358)\tLoss 0.4653 (0.4653)\tPrec 86.719% (86.719%)\n",
      "Epoch: [17][300/391]\tTime 0.055 (0.058)\tData 0.002 (0.005)\tLoss 0.4849 (0.4453)\tPrec 81.250% (84.936%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.338 (0.338)\tLoss 0.5377 (0.5377)\tPrec 81.250% (81.250%)\n",
      " * Prec 80.690% \n",
      "best acc: 83.480000\n",
      "Epoch: [18][0/391]\tTime 0.466 (0.466)\tData 0.408 (0.408)\tLoss 0.4532 (0.4532)\tPrec 86.719% (86.719%)\n",
      "Epoch: [18][300/391]\tTime 0.055 (0.058)\tData 0.002 (0.005)\tLoss 0.3594 (0.4263)\tPrec 88.281% (85.460%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.498 (0.498)\tLoss 0.6514 (0.6514)\tPrec 78.906% (78.906%)\n",
      " * Prec 78.010% \n",
      "best acc: 83.480000\n",
      "Epoch: [19][0/391]\tTime 0.468 (0.468)\tData 0.414 (0.414)\tLoss 0.5181 (0.5181)\tPrec 85.156% (85.156%)\n",
      "Epoch: [19][300/391]\tTime 0.055 (0.057)\tData 0.002 (0.004)\tLoss 0.4288 (0.4055)\tPrec 85.938% (86.083%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.371 (0.371)\tLoss 0.5904 (0.5904)\tPrec 79.688% (79.688%)\n",
      " * Prec 80.990% \n",
      "best acc: 83.480000\n",
      "Epoch: [20][0/391]\tTime 0.379 (0.379)\tData 0.327 (0.327)\tLoss 0.4625 (0.4625)\tPrec 84.375% (84.375%)\n",
      "Epoch: [20][300/391]\tTime 0.056 (0.057)\tData 0.002 (0.003)\tLoss 0.4482 (0.3848)\tPrec 85.156% (86.724%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.353 (0.353)\tLoss 0.4504 (0.4504)\tPrec 85.938% (85.938%)\n",
      " * Prec 83.220% \n",
      "best acc: 83.480000\n",
      "Epoch: [21][0/391]\tTime 0.357 (0.357)\tData 0.301 (0.301)\tLoss 0.3030 (0.3030)\tPrec 87.500% (87.500%)\n",
      "Epoch: [21][300/391]\tTime 0.055 (0.057)\tData 0.001 (0.003)\tLoss 0.4241 (0.3697)\tPrec 82.812% (87.336%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.304 (0.304)\tLoss 0.5542 (0.5542)\tPrec 81.250% (81.250%)\n",
      " * Prec 82.800% \n",
      "best acc: 83.480000\n",
      "Epoch: [22][0/391]\tTime 0.447 (0.447)\tData 0.395 (0.395)\tLoss 0.3010 (0.3010)\tPrec 89.062% (89.062%)\n",
      "Epoch: [22][300/391]\tTime 0.055 (0.058)\tData 0.001 (0.004)\tLoss 0.2298 (0.3579)\tPrec 89.844% (87.780%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.395 (0.395)\tLoss 0.3434 (0.3434)\tPrec 89.062% (89.062%)\n",
      " * Prec 84.520% \n",
      "best acc: 84.520000\n",
      "Epoch: [23][0/391]\tTime 0.410 (0.410)\tData 0.357 (0.357)\tLoss 0.2830 (0.2830)\tPrec 89.062% (89.062%)\n",
      "Epoch: [23][300/391]\tTime 0.056 (0.056)\tData 0.001 (0.003)\tLoss 0.3336 (0.3405)\tPrec 87.500% (88.421%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.376 (0.376)\tLoss 0.3888 (0.3888)\tPrec 88.281% (88.281%)\n",
      " * Prec 84.730% \n",
      "best acc: 84.730000\n",
      "Epoch: [24][0/391]\tTime 0.448 (0.448)\tData 0.390 (0.390)\tLoss 0.4246 (0.4246)\tPrec 84.375% (84.375%)\n",
      "Epoch: [24][300/391]\tTime 0.053 (0.057)\tData 0.001 (0.003)\tLoss 0.3106 (0.3218)\tPrec 89.844% (88.992%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.326 (0.326)\tLoss 0.3346 (0.3346)\tPrec 87.500% (87.500%)\n",
      " * Prec 85.820% \n",
      "best acc: 85.820000\n",
      "Epoch: [25][0/391]\tTime 0.407 (0.407)\tData 0.354 (0.354)\tLoss 0.3025 (0.3025)\tPrec 90.625% (90.625%)\n",
      "Epoch: [25][300/391]\tTime 0.053 (0.056)\tData 0.001 (0.003)\tLoss 0.3996 (0.3181)\tPrec 87.500% (89.182%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.323 (0.323)\tLoss 0.4345 (0.4345)\tPrec 86.719% (86.719%)\n",
      " * Prec 82.980% \n",
      "best acc: 85.820000\n",
      "Epoch: [26][0/391]\tTime 0.379 (0.379)\tData 0.326 (0.326)\tLoss 0.2219 (0.2219)\tPrec 92.188% (92.188%)\n",
      "Epoch: [26][300/391]\tTime 0.056 (0.056)\tData 0.002 (0.003)\tLoss 0.4918 (0.3002)\tPrec 80.469% (89.665%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.392 (0.392)\tLoss 0.3452 (0.3452)\tPrec 88.281% (88.281%)\n",
      " * Prec 86.190% \n",
      "best acc: 86.190000\n",
      "Epoch: [27][0/391]\tTime 0.508 (0.508)\tData 0.457 (0.457)\tLoss 0.4108 (0.4108)\tPrec 89.062% (89.062%)\n",
      "Epoch: [27][300/391]\tTime 0.058 (0.057)\tData 0.002 (0.003)\tLoss 0.3115 (0.2915)\tPrec 89.062% (89.994%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.317 (0.317)\tLoss 0.3285 (0.3285)\tPrec 89.844% (89.844%)\n",
      " * Prec 85.690% \n",
      "best acc: 86.190000\n",
      "Epoch: [28][0/391]\tTime 0.458 (0.458)\tData 0.398 (0.398)\tLoss 0.1754 (0.1754)\tPrec 92.188% (92.188%)\n",
      "Epoch: [28][300/391]\tTime 0.055 (0.057)\tData 0.001 (0.003)\tLoss 0.2222 (0.2790)\tPrec 90.625% (90.384%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.300 (0.300)\tLoss 0.4396 (0.4396)\tPrec 84.375% (84.375%)\n",
      " * Prec 85.710% \n",
      "best acc: 86.190000\n",
      "Epoch: [29][0/391]\tTime 0.411 (0.411)\tData 0.358 (0.358)\tLoss 0.1890 (0.1890)\tPrec 95.312% (95.312%)\n",
      "Epoch: [29][300/391]\tTime 0.055 (0.056)\tData 0.001 (0.003)\tLoss 0.2566 (0.2684)\tPrec 92.969% (90.827%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.388 (0.388)\tLoss 0.3101 (0.3101)\tPrec 89.844% (89.844%)\n",
      " * Prec 86.400% \n",
      "best acc: 86.400000\n",
      "Epoch: [30][0/391]\tTime 0.441 (0.441)\tData 0.387 (0.387)\tLoss 0.2907 (0.2907)\tPrec 89.062% (89.062%)\n",
      "Epoch: [30][300/391]\tTime 0.057 (0.057)\tData 0.002 (0.003)\tLoss 0.2103 (0.2596)\tPrec 94.531% (91.180%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.403 (0.403)\tLoss 0.3364 (0.3364)\tPrec 89.062% (89.062%)\n",
      " * Prec 85.720% \n",
      "best acc: 86.400000\n",
      "Epoch: [31][0/391]\tTime 0.419 (0.419)\tData 0.372 (0.372)\tLoss 0.1694 (0.1694)\tPrec 94.531% (94.531%)\n",
      "Epoch: [31][300/391]\tTime 0.056 (0.056)\tData 0.002 (0.003)\tLoss 0.2783 (0.2571)\tPrec 88.281% (91.139%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.442 (0.442)\tLoss 0.3418 (0.3418)\tPrec 91.406% (91.406%)\n",
      " * Prec 85.990% \n",
      "best acc: 86.400000\n",
      "Epoch: [32][0/391]\tTime 0.368 (0.368)\tData 0.322 (0.322)\tLoss 0.2350 (0.2350)\tPrec 90.625% (90.625%)\n",
      "Epoch: [32][300/391]\tTime 0.058 (0.056)\tData 0.002 (0.003)\tLoss 0.3754 (0.2412)\tPrec 86.719% (91.759%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.290 (0.290)\tLoss 0.2870 (0.2870)\tPrec 91.406% (91.406%)\n",
      " * Prec 85.560% \n",
      "best acc: 86.400000\n",
      "Epoch: [33][0/391]\tTime 0.457 (0.457)\tData 0.403 (0.403)\tLoss 0.1563 (0.1563)\tPrec 94.531% (94.531%)\n",
      "Epoch: [33][300/391]\tTime 0.054 (0.056)\tData 0.001 (0.003)\tLoss 0.3911 (0.2315)\tPrec 85.156% (92.011%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.383 (0.383)\tLoss 0.2774 (0.2774)\tPrec 87.500% (87.500%)\n",
      " * Prec 87.310% \n",
      "best acc: 87.310000\n",
      "Epoch: [34][0/391]\tTime 0.510 (0.510)\tData 0.458 (0.458)\tLoss 0.3300 (0.3300)\tPrec 88.281% (88.281%)\n",
      "Epoch: [34][300/391]\tTime 0.055 (0.057)\tData 0.001 (0.003)\tLoss 0.2157 (0.2295)\tPrec 93.750% (92.203%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.356 (0.356)\tLoss 0.3336 (0.3336)\tPrec 87.500% (87.500%)\n",
      " * Prec 87.200% \n",
      "best acc: 87.310000\n",
      "Epoch: [35][0/391]\tTime 0.542 (0.542)\tData 0.486 (0.486)\tLoss 0.2040 (0.2040)\tPrec 92.969% (92.969%)\n",
      "Epoch: [35][300/391]\tTime 0.055 (0.057)\tData 0.001 (0.003)\tLoss 0.1055 (0.2108)\tPrec 98.438% (92.678%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.395 (0.395)\tLoss 0.3542 (0.3542)\tPrec 89.062% (89.062%)\n",
      " * Prec 87.400% \n",
      "best acc: 87.400000\n",
      "Epoch: [36][0/391]\tTime 0.455 (0.455)\tData 0.401 (0.401)\tLoss 0.2217 (0.2217)\tPrec 92.969% (92.969%)\n",
      "Epoch: [36][300/391]\tTime 0.055 (0.056)\tData 0.001 (0.003)\tLoss 0.1639 (0.2050)\tPrec 92.969% (93.021%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.383 (0.383)\tLoss 0.3489 (0.3489)\tPrec 89.062% (89.062%)\n",
      " * Prec 86.800% \n",
      "best acc: 87.400000\n",
      "Epoch: [37][0/391]\tTime 0.442 (0.442)\tData 0.389 (0.389)\tLoss 0.1123 (0.1123)\tPrec 94.531% (94.531%)\n",
      "Epoch: [37][300/391]\tTime 0.055 (0.056)\tData 0.001 (0.003)\tLoss 0.1749 (0.2056)\tPrec 92.969% (93.026%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.348 (0.348)\tLoss 0.2642 (0.2642)\tPrec 89.844% (89.844%)\n",
      " * Prec 87.330% \n",
      "best acc: 87.400000\n",
      "Epoch: [38][0/391]\tTime 0.423 (0.423)\tData 0.368 (0.368)\tLoss 0.1396 (0.1396)\tPrec 94.531% (94.531%)\n",
      "Epoch: [38][300/391]\tTime 0.055 (0.056)\tData 0.001 (0.003)\tLoss 0.1892 (0.1995)\tPrec 92.188% (93.143%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.330 (0.330)\tLoss 0.3371 (0.3371)\tPrec 90.625% (90.625%)\n",
      " * Prec 87.010% \n",
      "best acc: 87.400000\n",
      "Epoch: [39][0/391]\tTime 0.422 (0.422)\tData 0.364 (0.364)\tLoss 0.1649 (0.1649)\tPrec 94.531% (94.531%)\n",
      "Epoch: [39][300/391]\tTime 0.051 (0.057)\tData 0.001 (0.003)\tLoss 0.1926 (0.1929)\tPrec 91.406% (93.270%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.415 (0.415)\tLoss 0.3251 (0.3251)\tPrec 90.625% (90.625%)\n",
      " * Prec 85.990% \n",
      "best acc: 87.400000\n",
      "Epoch: [40][0/391]\tTime 0.392 (0.392)\tData 0.339 (0.339)\tLoss 0.2816 (0.2816)\tPrec 89.844% (89.844%)\n",
      "Epoch: [40][300/391]\tTime 0.055 (0.057)\tData 0.001 (0.003)\tLoss 0.1619 (0.1905)\tPrec 94.531% (93.407%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.364 (0.364)\tLoss 0.3500 (0.3500)\tPrec 88.281% (88.281%)\n",
      " * Prec 88.110% \n",
      "best acc: 88.110000\n",
      "Epoch: [41][0/391]\tTime 0.455 (0.455)\tData 0.402 (0.402)\tLoss 0.1140 (0.1140)\tPrec 96.094% (96.094%)\n",
      "Epoch: [41][300/391]\tTime 0.055 (0.057)\tData 0.001 (0.003)\tLoss 0.1465 (0.1824)\tPrec 94.531% (93.649%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.393 (0.393)\tLoss 0.4129 (0.4129)\tPrec 88.281% (88.281%)\n",
      " * Prec 86.020% \n",
      "best acc: 88.110000\n",
      "Epoch: [42][0/391]\tTime 0.562 (0.562)\tData 0.508 (0.508)\tLoss 0.1138 (0.1138)\tPrec 95.312% (95.312%)\n",
      "Epoch: [42][300/391]\tTime 0.055 (0.057)\tData 0.001 (0.004)\tLoss 0.0691 (0.1763)\tPrec 97.656% (93.846%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.455 (0.455)\tLoss 0.2884 (0.2884)\tPrec 89.062% (89.062%)\n",
      " * Prec 87.720% \n",
      "best acc: 88.110000\n",
      "Epoch: [43][0/391]\tTime 0.433 (0.433)\tData 0.379 (0.379)\tLoss 0.1841 (0.1841)\tPrec 91.406% (91.406%)\n",
      "Epoch: [43][300/391]\tTime 0.055 (0.056)\tData 0.001 (0.003)\tLoss 0.2221 (0.1752)\tPrec 91.406% (93.919%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.335 (0.335)\tLoss 0.3022 (0.3022)\tPrec 89.062% (89.062%)\n",
      " * Prec 87.790% \n",
      "best acc: 88.110000\n",
      "Epoch: [44][0/391]\tTime 0.441 (0.441)\tData 0.388 (0.388)\tLoss 0.0937 (0.0937)\tPrec 96.094% (96.094%)\n",
      "Epoch: [44][300/391]\tTime 0.055 (0.057)\tData 0.001 (0.003)\tLoss 0.1882 (0.1618)\tPrec 92.969% (94.360%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.354 (0.354)\tLoss 0.2727 (0.2727)\tPrec 89.844% (89.844%)\n",
      " * Prec 88.040% \n",
      "best acc: 88.110000\n",
      "Epoch: [45][0/391]\tTime 0.531 (0.531)\tData 0.479 (0.479)\tLoss 0.1655 (0.1655)\tPrec 92.969% (92.969%)\n",
      "Epoch: [45][300/391]\tTime 0.055 (0.057)\tData 0.001 (0.004)\tLoss 0.1742 (0.1595)\tPrec 96.094% (94.469%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.365 (0.365)\tLoss 0.2156 (0.2156)\tPrec 93.750% (93.750%)\n",
      " * Prec 86.790% \n",
      "best acc: 88.110000\n",
      "Epoch: [46][0/391]\tTime 0.456 (0.456)\tData 0.403 (0.403)\tLoss 0.0793 (0.0793)\tPrec 96.875% (96.875%)\n",
      "Epoch: [46][300/391]\tTime 0.055 (0.057)\tData 0.002 (0.003)\tLoss 0.0821 (0.1577)\tPrec 97.656% (94.591%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.443 (0.443)\tLoss 0.3366 (0.3366)\tPrec 90.625% (90.625%)\n",
      " * Prec 88.150% \n",
      "best acc: 88.150000\n",
      "Epoch: [47][0/391]\tTime 0.420 (0.420)\tData 0.367 (0.367)\tLoss 0.1797 (0.1797)\tPrec 92.969% (92.969%)\n",
      "Epoch: [47][300/391]\tTime 0.054 (0.057)\tData 0.002 (0.004)\tLoss 0.1518 (0.1501)\tPrec 95.312% (94.900%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.353 (0.353)\tLoss 0.2801 (0.2801)\tPrec 89.062% (89.062%)\n",
      " * Prec 87.210% \n",
      "best acc: 88.150000\n",
      "Epoch: [48][0/391]\tTime 0.512 (0.512)\tData 0.459 (0.459)\tLoss 0.1134 (0.1134)\tPrec 97.656% (97.656%)\n",
      "Epoch: [48][300/391]\tTime 0.055 (0.057)\tData 0.001 (0.004)\tLoss 0.1178 (0.1516)\tPrec 96.875% (94.843%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.300 (0.300)\tLoss 0.2096 (0.2096)\tPrec 93.750% (93.750%)\n",
      " * Prec 88.910% \n",
      "best acc: 88.910000\n",
      "Epoch: [49][0/391]\tTime 0.408 (0.408)\tData 0.349 (0.349)\tLoss 0.1313 (0.1313)\tPrec 94.531% (94.531%)\n",
      "Epoch: [49][300/391]\tTime 0.073 (0.057)\tData 0.031 (0.004)\tLoss 0.1644 (0.1451)\tPrec 92.969% (95.027%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.457 (0.457)\tLoss 0.4251 (0.4251)\tPrec 87.500% (87.500%)\n",
      " * Prec 86.430% \n",
      "best acc: 88.910000\n",
      "Epoch: [50][0/391]\tTime 0.523 (0.523)\tData 0.465 (0.465)\tLoss 0.1174 (0.1174)\tPrec 94.531% (94.531%)\n",
      "Epoch: [50][300/391]\tTime 0.057 (0.057)\tData 0.001 (0.003)\tLoss 0.1674 (0.1420)\tPrec 93.750% (95.113%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.348 (0.348)\tLoss 0.2994 (0.2994)\tPrec 88.281% (88.281%)\n",
      " * Prec 87.940% \n",
      "best acc: 88.910000\n",
      "Epoch: [51][0/391]\tTime 0.471 (0.471)\tData 0.421 (0.421)\tLoss 0.0913 (0.0913)\tPrec 95.312% (95.312%)\n",
      "Epoch: [51][300/391]\tTime 0.055 (0.057)\tData 0.001 (0.003)\tLoss 0.0876 (0.1364)\tPrec 95.312% (95.250%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.437 (0.437)\tLoss 0.4400 (0.4400)\tPrec 84.375% (84.375%)\n",
      " * Prec 88.170% \n",
      "best acc: 88.910000\n",
      "Epoch: [52][0/391]\tTime 0.436 (0.436)\tData 0.385 (0.385)\tLoss 0.1730 (0.1730)\tPrec 94.531% (94.531%)\n",
      "Epoch: [52][300/391]\tTime 0.055 (0.056)\tData 0.001 (0.003)\tLoss 0.0871 (0.1373)\tPrec 98.438% (95.344%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.352 (0.352)\tLoss 0.2575 (0.2575)\tPrec 92.969% (92.969%)\n",
      " * Prec 88.160% \n",
      "best acc: 88.910000\n",
      "Epoch: [53][0/391]\tTime 0.395 (0.395)\tData 0.344 (0.344)\tLoss 0.0781 (0.0781)\tPrec 96.094% (96.094%)\n",
      "Epoch: [53][300/391]\tTime 0.059 (0.056)\tData 0.002 (0.003)\tLoss 0.1737 (0.1298)\tPrec 93.750% (95.453%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.425 (0.425)\tLoss 0.3495 (0.3495)\tPrec 90.625% (90.625%)\n",
      " * Prec 88.260% \n",
      "best acc: 88.910000\n",
      "Epoch: [54][0/391]\tTime 0.471 (0.471)\tData 0.421 (0.421)\tLoss 0.1058 (0.1058)\tPrec 94.531% (94.531%)\n",
      "Epoch: [54][300/391]\tTime 0.055 (0.056)\tData 0.002 (0.003)\tLoss 0.0965 (0.1329)\tPrec 95.312% (95.310%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.386 (0.386)\tLoss 0.3016 (0.3016)\tPrec 87.500% (87.500%)\n",
      " * Prec 88.120% \n",
      "best acc: 88.910000\n",
      "Epoch: [55][0/391]\tTime 0.517 (0.517)\tData 0.458 (0.458)\tLoss 0.0876 (0.0876)\tPrec 96.875% (96.875%)\n",
      "Epoch: [55][300/391]\tTime 0.053 (0.057)\tData 0.002 (0.003)\tLoss 0.0618 (0.1244)\tPrec 97.656% (95.699%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.400 (0.400)\tLoss 0.4157 (0.4157)\tPrec 86.719% (86.719%)\n",
      " * Prec 87.420% \n",
      "best acc: 88.910000\n",
      "Epoch: [56][0/391]\tTime 0.445 (0.445)\tData 0.390 (0.390)\tLoss 0.1643 (0.1643)\tPrec 94.531% (94.531%)\n",
      "Epoch: [56][300/391]\tTime 0.055 (0.056)\tData 0.001 (0.003)\tLoss 0.2138 (0.1235)\tPrec 93.750% (95.694%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.364 (0.364)\tLoss 0.2472 (0.2472)\tPrec 89.062% (89.062%)\n",
      " * Prec 88.900% \n",
      "best acc: 88.910000\n",
      "Epoch: [57][0/391]\tTime 0.458 (0.458)\tData 0.406 (0.406)\tLoss 0.1551 (0.1551)\tPrec 96.094% (96.094%)\n",
      "Epoch: [57][300/391]\tTime 0.055 (0.056)\tData 0.001 (0.003)\tLoss 0.1127 (0.1172)\tPrec 97.656% (95.964%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.372 (0.372)\tLoss 0.2683 (0.2683)\tPrec 91.406% (91.406%)\n",
      " * Prec 88.210% \n",
      "best acc: 88.910000\n",
      "Epoch: [58][0/391]\tTime 0.554 (0.554)\tData 0.508 (0.508)\tLoss 0.0430 (0.0430)\tPrec 99.219% (99.219%)\n",
      "Epoch: [58][300/391]\tTime 0.055 (0.057)\tData 0.001 (0.003)\tLoss 0.0654 (0.1136)\tPrec 97.656% (95.974%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.303 (0.303)\tLoss 0.3296 (0.3296)\tPrec 88.281% (88.281%)\n",
      " * Prec 88.290% \n",
      "best acc: 88.910000\n",
      "Epoch: [59][0/391]\tTime 0.445 (0.445)\tData 0.392 (0.392)\tLoss 0.1208 (0.1208)\tPrec 95.312% (95.312%)\n",
      "Epoch: [59][300/391]\tTime 0.055 (0.056)\tData 0.002 (0.003)\tLoss 0.0295 (0.1110)\tPrec 100.000% (96.120%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.355 (0.355)\tLoss 0.3091 (0.3091)\tPrec 89.844% (89.844%)\n",
      " * Prec 89.070% \n",
      "best acc: 89.070000\n",
      "Epoch: [60][0/391]\tTime 0.454 (0.454)\tData 0.399 (0.399)\tLoss 0.1809 (0.1809)\tPrec 91.406% (91.406%)\n",
      "Epoch: [60][300/391]\tTime 0.055 (0.057)\tData 0.001 (0.003)\tLoss 0.0822 (0.1133)\tPrec 97.656% (95.951%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.333 (0.333)\tLoss 0.4300 (0.4300)\tPrec 90.625% (90.625%)\n",
      " * Prec 85.250% \n",
      "best acc: 89.070000\n",
      "Epoch: [61][0/391]\tTime 0.534 (0.534)\tData 0.484 (0.484)\tLoss 0.1208 (0.1208)\tPrec 95.312% (95.312%)\n",
      "Epoch: [61][300/391]\tTime 0.052 (0.057)\tData 0.002 (0.003)\tLoss 0.1164 (0.1150)\tPrec 96.094% (95.972%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.355 (0.355)\tLoss 0.3913 (0.3913)\tPrec 90.625% (90.625%)\n",
      " * Prec 88.050% \n",
      "best acc: 89.070000\n",
      "Epoch: [62][0/391]\tTime 0.371 (0.371)\tData 0.317 (0.317)\tLoss 0.1076 (0.1076)\tPrec 96.875% (96.875%)\n",
      "Epoch: [62][300/391]\tTime 0.055 (0.056)\tData 0.001 (0.003)\tLoss 0.1750 (0.1034)\tPrec 95.312% (96.468%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.424 (0.424)\tLoss 0.3588 (0.3588)\tPrec 89.062% (89.062%)\n",
      " * Prec 89.510% \n",
      "best acc: 89.510000\n",
      "Epoch: [63][0/391]\tTime 0.508 (0.508)\tData 0.456 (0.456)\tLoss 0.0497 (0.0497)\tPrec 97.656% (97.656%)\n",
      "Epoch: [63][300/391]\tTime 0.055 (0.057)\tData 0.001 (0.003)\tLoss 0.0765 (0.1050)\tPrec 98.438% (96.421%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.391 (0.391)\tLoss 0.3459 (0.3459)\tPrec 90.625% (90.625%)\n",
      " * Prec 88.970% \n",
      "best acc: 89.510000\n",
      "Epoch: [64][0/391]\tTime 0.448 (0.448)\tData 0.393 (0.393)\tLoss 0.0455 (0.0455)\tPrec 98.438% (98.438%)\n",
      "Epoch: [64][300/391]\tTime 0.055 (0.056)\tData 0.001 (0.003)\tLoss 0.0419 (0.0989)\tPrec 99.219% (96.618%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.340 (0.340)\tLoss 0.2741 (0.2741)\tPrec 91.406% (91.406%)\n",
      " * Prec 88.170% \n",
      "best acc: 89.510000\n",
      "Epoch: [65][0/391]\tTime 0.435 (0.435)\tData 0.386 (0.386)\tLoss 0.0613 (0.0613)\tPrec 97.656% (97.656%)\n",
      "Epoch: [65][300/391]\tTime 0.052 (0.057)\tData 0.002 (0.004)\tLoss 0.1428 (0.1051)\tPrec 93.750% (96.333%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.320 (0.320)\tLoss 0.3234 (0.3234)\tPrec 89.844% (89.844%)\n",
      " * Prec 88.280% \n",
      "best acc: 89.510000\n",
      "Epoch: [66][0/391]\tTime 0.480 (0.480)\tData 0.429 (0.429)\tLoss 0.1089 (0.1089)\tPrec 94.531% (94.531%)\n",
      "Epoch: [66][300/391]\tTime 0.055 (0.057)\tData 0.001 (0.004)\tLoss 0.0773 (0.0957)\tPrec 97.656% (96.686%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.323 (0.323)\tLoss 0.3863 (0.3863)\tPrec 88.281% (88.281%)\n",
      " * Prec 88.120% \n",
      "best acc: 89.510000\n",
      "Epoch: [67][0/391]\tTime 0.467 (0.467)\tData 0.417 (0.417)\tLoss 0.0617 (0.0617)\tPrec 99.219% (99.219%)\n",
      "Epoch: [67][300/391]\tTime 0.055 (0.056)\tData 0.001 (0.003)\tLoss 0.0730 (0.0980)\tPrec 98.438% (96.657%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.354 (0.354)\tLoss 0.4159 (0.4159)\tPrec 88.281% (88.281%)\n",
      " * Prec 88.800% \n",
      "best acc: 89.510000\n",
      "Epoch: [68][0/391]\tTime 0.395 (0.395)\tData 0.342 (0.342)\tLoss 0.1036 (0.1036)\tPrec 96.875% (96.875%)\n",
      "Epoch: [68][300/391]\tTime 0.055 (0.056)\tData 0.001 (0.003)\tLoss 0.1036 (0.0967)\tPrec 97.656% (96.602%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.417 (0.417)\tLoss 0.4974 (0.4974)\tPrec 87.500% (87.500%)\n",
      " * Prec 88.370% \n",
      "best acc: 89.510000\n",
      "Epoch: [69][0/391]\tTime 0.393 (0.393)\tData 0.343 (0.343)\tLoss 0.1373 (0.1373)\tPrec 93.750% (93.750%)\n",
      "Epoch: [69][300/391]\tTime 0.051 (0.056)\tData 0.002 (0.003)\tLoss 0.1006 (0.0972)\tPrec 96.875% (96.647%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.316 (0.316)\tLoss 0.2010 (0.2010)\tPrec 94.531% (94.531%)\n",
      " * Prec 90.110% \n",
      "best acc: 90.110000\n"
     ]
    }
   ],
   "source": [
    "lr = 4e-2\n",
    "weight_decay = 1e-4\n",
    "epochs = 150\n",
    "best_prec = 0\n",
    "\n",
    "model.cuda()\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=weight_decay)\n",
    "#cudnn.benchmark = True\n",
    "\n",
    "fdir = '/home/pnataraj/private/ece284_saved_models/'+str(model_name)\n",
    "if not os.path.exists(fdir):\n",
    "    os.makedirs(fdir)     \n",
    "\n",
    "for epoch in range(0, epochs):\n",
    "    adjust_learning_rate(optimizer, epoch)\n",
    "\n",
    "    train(trainloader, model, criterion, optimizer, epoch)\n",
    "    \n",
    "    # evaluate on test set\n",
    "    print(\"Validation starts\")\n",
    "    prec = validate(testloader, model, criterion)\n",
    "\n",
    "    # remember best precision and save checkpoint\n",
    "    is_best = prec > best_prec\n",
    "    best_prec = max(prec,best_prec)\n",
    "    print('best acc: {:1f}'.format(best_prec))\n",
    "    save_checkpoint({\n",
    "        'epoch': epoch + 1,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'best_prec': best_prec,\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "    }, is_best, fdir)\n",
    "    if best_prec > 90:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3a7c2458-9f8c-43cc-89ea-25c9a1d181dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Accuracy: 9011/10000 (90%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "PATH = '/home/pnataraj/private/ece284_saved_models/vggnet_quant4/model_best.pth.tar'\n",
    "checkpoint = torch.load(PATH)\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "device = torch.device(\"cuda\") \n",
    "\n",
    "model.cuda()\n",
    "model.eval()\n",
    "\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, target in testloader:\n",
    "        data, target = data.to(device), target.to(device) # loading to GPU\n",
    "        output = model(data)\n",
    "        pred = output.argmax(dim=1, keepdim=True)  \n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "test_loss /= len(testloader.dataset)\n",
    "\n",
    "print('\\nTest set: Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        correct, len(testloader.dataset),\n",
    "        100. * correct / len(testloader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ea1df997-a5fb-4c97-a65f-f005524fc8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SaveOutput:\n",
    "    def __init__(self):\n",
    "        self.outputs = []\n",
    "    def __call__(self, module, module_in):\n",
    "        self.outputs.append(module_in)\n",
    "    def clear(self):\n",
    "        self.outputs = []  \n",
    "        \n",
    "######### Save inputs from selected layer ##########\n",
    "save_output = SaveOutput()\n",
    "i = 0\n",
    "\n",
    "for layer in model.modules():\n",
    "    i = i+1\n",
    "    if isinstance(layer, QuantConv2d):\n",
    "        # print(i,\"-th layer prehooked\")\n",
    "        layer.register_forward_pre_hook(save_output)             \n",
    "####################################################\n",
    "\n",
    "dataiter = iter(testloader)\n",
    "images, labels = next(dataiter)\n",
    "images = images.to(device)\n",
    "out = model(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a4a852cb-a081-400d-8a9b-b27ddd0ae703",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_q = model.features[3].weight_q\n",
    "w_alpha = model.features[3].weight_quant.wgt_alpha\n",
    "w_bit = 4\n",
    "\n",
    "weight_int = weight_q / (w_alpha / (2**(w_bit-1)-1))\n",
    "# print(weight_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e41b4694-71ad-4597-882f-5e7855f96202",
   "metadata": {},
   "outputs": [],
   "source": [
    "act = save_output.outputs[1][0]\n",
    "act_alpha  = model.features[3].act_alpha\n",
    "act_bit = 4\n",
    "act_quant_fn = act_quantization(act_bit)\n",
    "\n",
    "act_q = act_quant_fn(act, act_alpha)\n",
    "\n",
    "act_int = act_q / (act_alpha / (2**act_bit-1))\n",
    "# print(act_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "9eeb1cd6-7b03-4151-ad54-7b7720e15ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4, 4, 1156])\n"
     ]
    }
   ],
   "source": [
    "a_int = act_int[0,:,:,:] # [64, 32, 32]\n",
    "\n",
    "w_int = torch.reshape(weight_int, (weight_int.size(0), weight_int.size(1), -1))  # merge ki, kj index to kij\n",
    "# w_int.weight.size() = torch.Size([64, 64, 9])\n",
    "\n",
    "padding = 1\n",
    "stride = 1\n",
    "array_size = 4\n",
    "\n",
    "numTiles = 16\n",
    "icTile = 4\n",
    "ocTile = 4\n",
    "\n",
    "nig = range(a_int.size(1))  ## ni group [0,1,...31]\n",
    "njg = range(a_int.size(2))  ## nj group\n",
    " \n",
    "icg = int(w_int.size(1)/numTiles)  # Num of channels per tile 64 / 16 = 4\n",
    "ocg = int(w_int.size(0)/numTiles)\n",
    "\n",
    "kijg = range(w_int.size(2)) # [0, .. 8]\n",
    "ki_dim = int(math.sqrt(w_int.size(2)))  ## Kernel's 1 dim size\n",
    "\n",
    "######## Padding before Convolution #######\n",
    "a_pad = torch.zeros(icTile, ocTile, icg, len(nig)+padding*2, len(njg)+padding*2).cuda()\n",
    "\n",
    "for in_tile in range(icg):\n",
    "    for out_tile in range(ocg):\n",
    "        start = in_tile * icg * ocg + out_tile * ocg\n",
    "        a_pad[in_tile, out_tile, :, padding:padding+len(nig), padding:padding+len(njg)] = a_int[start:start+4,:,:].cuda()\n",
    "\n",
    "\n",
    "# a_pad[ :, padding:padding+len(nig), padding:padding+len(njg)] = a_int.cuda()\n",
    "a_pad = torch.reshape(a_pad, (a_pad.size(0), a_pad.size(1), a_pad.size(2), -1))\n",
    "print(a_pad.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "5628fc6a-f3e0-4726-8231-2d8f07318d32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "w_int.cuda()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34280e3b-34f6-4999-a506-ac1ba0955b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_nijg = range(a_pad.size(3))\n",
    "psum = torch.zeros(icTile, ocTile, array_size, len(p_nijg), len(kijg)).cuda()\n",
    "\n",
    "for kij in kijg:\n",
    "    for nij in p_nijg:\n",
    "        for out_tile in range(ocTile):\n",
    "            for in_tile in range(icTile):\n",
    "                for out_ch in range(ocg):\n",
    "                    for in_ch in range(icg):\n",
    "                        w_in_ind = (in_tile * icg * ocg + out_tile * ocg) + in_ch\n",
    "                        psum[in_tile, out_tile, out_ch, nij, kij] += w_int[:, w_in_ind, kij].sum() * a_pad[in_tile, out_tile, in_ch, nij].cuda()\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ad219826-1f87-4219-9be6-4f6d50d6e9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "a_pad_ni_dim = int(math.sqrt(a_pad.size(1))) # 32 + 2*pad = 34\n",
    "\n",
    "o_ni_dim = int((a_pad_ni_dim - (ki_dim- 1) - 1)/stride + 1) #34 - 2 - 1 + 1 = 32\n",
    "o_nijg = range(o_ni_dim**2) # [0, 32*32-1]    \n",
    "    \n",
    "out = torch.zeros(len(ocg), len(o_nijg)).cuda()\n",
    "  \n",
    "   \n",
    "### SFP accumulation ###\n",
    "for o_nij in o_nijg: \n",
    "    for kij in kijg:  #[0, ... 8]\n",
    "        out[:,o_nij] = out[:,o_nij] + \\\n",
    "        psum[:, int(o_nij/o_ni_dim)*a_pad_ni_dim + o_nij%o_ni_dim + int(kij/ki_dim)*a_pad_ni_dim + kij%ki_dim, kij]\n",
    "                ## 2nd index = (int(o_nij/30)*32 + o_nij%30) + (int(kij/3)*32 + kij%3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3f168d-8467-410c-9dd4-cee476550d79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
